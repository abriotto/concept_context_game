{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_results import *\n",
    "from utils.plot_helpers import *\n",
    "\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('default')\n",
    "import torch\n",
    "from utils.analysis_from_interaction import *\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "import os\n",
    "if not os.path.exists('analysis'):\n",
    "    os.makedirs('analysis')\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['(3,4)', '(3,8)', '(3,16)', '(4,4)', '(4,8)', '(5,4)']\n",
    "n_values = [4, 8, 16, 4, 8, 4]\n",
    "n_attributes = [3, 3, 3, 4, 4, 5]\n",
    "n_epochs = 300\n",
    "n_datasets = len(datasets)\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['(3,4)']\n",
    "n_values = [4,]\n",
    "n_attributes = [3,]\n",
    "n_epochs = 300\n",
    "n_datasets = len(datasets)\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_unaware = False # whether original or context_unaware simulations are evaluated\n",
    "\n",
    "setting = 'standard'\n",
    "granularity_list = ['coarse', 'mixed', 'fine']\n",
    "non_default_gran_list = ['coarse', 'fine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Define the directory and filename for the CSV file\n",
    "output_folder = 'analysis'\n",
    "csv_filename = os.path.join(output_folder, '00_vocab_sizes.csv')\n",
    "\n",
    "# Check if the output folder exists, if not, create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Check if the CSV file exists, if not, create it with headers\n",
    "fieldnames = ['dataset', 'context_condition', 'vocab_size', 'symbols']\n",
    "file_exists = os.path.exists(csv_filename)\n",
    "with open(csv_filename, 'a', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "# Open the file in append mode and write the vocab sizes for each dataset\n",
    "with open(csv_filename, 'a', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Go through all datasets\n",
    "    for i, d in enumerate(datasets):\n",
    "        for g in granularity_list:\n",
    "            # select first run\n",
    "            if g != 'mixed':\n",
    "                path_to_run = paths[i] + '/' + str(setting) + '/' + 'granularity_' + g + '/' + str(0) + '/'\n",
    "                path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "                \n",
    "                messages = interaction.message.argmax(dim=-1)\n",
    "                messages = [msg.tolist() for msg in messages]\n",
    "                all_symbols = [symbol for message in messages for symbol in message]\n",
    "                symbol_counts = Counter(all_symbols)\n",
    "                vocab_size = len(symbol_counts)\n",
    "\n",
    "            elif g == 'mixed':\n",
    "                path_to_run = paths[i] + '/' + str(setting) + '/' + str(0) + '/'\n",
    "                path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "                \n",
    "                messages = interaction.message.argmax(dim=-1)\n",
    "                messages = [msg.tolist() for msg in messages]\n",
    "                all_symbols = [symbol for message in messages for symbol in message]\n",
    "                symbol_counts = Counter(all_symbols)\n",
    "                vocab_size = len(symbol_counts)\n",
    "            \n",
    "            writer.writerow({'dataset': d, 'context_condition': g, 'vocab_size': vocab_size, 'symbols': symbol_counts})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>context_condition</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>12</td>\n",
       "      <td>Counter({0: 742, 14: 450, 9: 391, 4: 387, 6: 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>15</td>\n",
       "      <td>Counter({0: 1807, 6: 779, 2: 582, 8: 537, 11: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>14</td>\n",
       "      <td>Counter({0: 742, 14: 332, 5: 315, 4: 214, 12: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>17</td>\n",
       "      <td>Counter({0: 4364, 16: 1585, 6: 1552, 17: 1485,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>28</td>\n",
       "      <td>Counter({0: 11662, 25: 4555, 2: 2113, 12: 2050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>fine</td>\n",
       "      <td>27</td>\n",
       "      <td>Counter({0: 4364, 23: 1292, 16: 947, 4: 872, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>32</td>\n",
       "      <td>Counter({0: 29467, 18: 15057, 47: 10339, 41: 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>52</td>\n",
       "      <td>Counter({0: 83302, 47: 18222, 12: 13188, 37: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>fine</td>\n",
       "      <td>52</td>\n",
       "      <td>Counter({0: 29467, 5: 8383, 22: 5202, 19: 4557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>15</td>\n",
       "      <td>Counter({0: 3743, 4: 2910, 14: 2438, 15: 1895,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>16</td>\n",
       "      <td>Counter({0: 12037, 5: 4438, 8: 4194, 12: 4184,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>16</td>\n",
       "      <td>Counter({0: 3742, 2: 2321, 9: 2298, 8: 1743, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>27</td>\n",
       "      <td>Counter({0: 39359, 13: 16903, 20: 14734, 21: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>28</td>\n",
       "      <td>Counter({0: 140159, 1: 56714, 24: 56647, 18: 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>fine</td>\n",
       "      <td>28</td>\n",
       "      <td>Counter({0: 39359, 5: 13260, 11: 12425, 4: 116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>16</td>\n",
       "      <td>Counter({0: 18742, 5: 14530, 1: 14096, 2: 1088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>16</td>\n",
       "      <td>Counter({0: 74669, 14: 59508, 7: 48712, 5: 348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>16</td>\n",
       "      <td>Counter({0: 18742, 12: 15979, 8: 10626, 4: 102...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset context_condition  vocab_size  \\\n",
       "0    (3,4)            coarse          12   \n",
       "1    (3,4)             mixed          15   \n",
       "2    (3,4)              fine          14   \n",
       "3    (3,8)            coarse          17   \n",
       "4    (3,8)             mixed          28   \n",
       "5    (3,8)              fine          27   \n",
       "6   (3,16)            coarse          32   \n",
       "7   (3,16)             mixed          52   \n",
       "8   (3,16)              fine          52   \n",
       "9    (4,4)            coarse          15   \n",
       "10   (4,4)             mixed          16   \n",
       "11   (4,4)              fine          16   \n",
       "12   (4,8)            coarse          27   \n",
       "13   (4,8)             mixed          28   \n",
       "14   (4,8)              fine          28   \n",
       "15   (5,4)            coarse          16   \n",
       "16   (5,4)             mixed          16   \n",
       "17   (5,4)              fine          16   \n",
       "\n",
       "                                              symbols  \n",
       "0   Counter({0: 742, 14: 450, 9: 391, 4: 387, 6: 2...  \n",
       "1   Counter({0: 1807, 6: 779, 2: 582, 8: 537, 11: ...  \n",
       "2   Counter({0: 742, 14: 332, 5: 315, 4: 214, 12: ...  \n",
       "3   Counter({0: 4364, 16: 1585, 6: 1552, 17: 1485,...  \n",
       "4   Counter({0: 11662, 25: 4555, 2: 2113, 12: 2050...  \n",
       "5   Counter({0: 4364, 23: 1292, 16: 947, 4: 872, 2...  \n",
       "6   Counter({0: 29467, 18: 15057, 47: 10339, 41: 6...  \n",
       "7   Counter({0: 83302, 47: 18222, 12: 13188, 37: 1...  \n",
       "8   Counter({0: 29467, 5: 8383, 22: 5202, 19: 4557...  \n",
       "9   Counter({0: 3743, 4: 2910, 14: 2438, 15: 1895,...  \n",
       "10  Counter({0: 12037, 5: 4438, 8: 4194, 12: 4184,...  \n",
       "11  Counter({0: 3742, 2: 2321, 9: 2298, 8: 1743, 5...  \n",
       "12  Counter({0: 39359, 13: 16903, 20: 14734, 21: 1...  \n",
       "13  Counter({0: 140159, 1: 56714, 24: 56647, 18: 3...  \n",
       "14  Counter({0: 39359, 5: 13260, 11: 12425, 4: 116...  \n",
       "15  Counter({0: 18742, 5: 14530, 1: 14096, 2: 1088...  \n",
       "16  Counter({0: 74669, 14: 59508, 7: 48712, 5: 348...  \n",
       "17  Counter({0: 18742, 12: 15979, 8: 10626, 4: 102...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('analysis/00_vocab_sizes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See which messages are produced for which concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['(3,4)',]\n",
    "n_values = [4]\n",
    "n_attributes = [3]\n",
    "n_epochs = 300\n",
    "n_datasets = len(datasets)\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all datasets\n",
    "for i, d in enumerate(datasets):\n",
    "    for g in non_default_gran_list:\n",
    "        if g != 'mixed':\n",
    "        # select first run\n",
    "            path_to_run = paths[i] + '/' + str(setting) +'/granularity_' + g +'/' + str(0) + '/'\n",
    "        else:\n",
    "            path_to_run = paths[i] + '/' + str(setting) +'/' + str(0) + '/'\n",
    "            \n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        print(path_to_interaction_train)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        sender_input = interaction.sender_input\n",
    "        print(sender_input.shape)\n",
    "        n_targets = int(sender_input.shape[1]/2)\n",
    "        # get target objects and fixed vectors to re-construct concepts\n",
    "        target_objects = sender_input[:, :n_targets]\n",
    "        target_objects = k_hot_to_attributes(target_objects, n_values[i])\n",
    "        # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "        (objects, fixed) = retrieve_concepts_sampling(target_objects, all_targets=True)\n",
    "        concepts = list(zip(objects, fixed))\n",
    "\n",
    "        # get distractor objects to re-construct context conditions\n",
    "        distractor_objects = sender_input[:, n_targets:]\n",
    "        distractor_objects = k_hot_to_attributes(distractor_objects, n_values[i])\n",
    "        context_conds = retrieve_context_condition(objects, fixed, distractor_objects)\n",
    "        #print(context_conds)\n",
    "\n",
    "        # get random qualitative samples\n",
    "        #fixed_index = random.randint(0, n_attributes[i]-1) # define a fixed index for the concept\n",
    "        n_fixed = random.randint(1, n_attributes[i]) # how many fixed attributes?\n",
    "        #n_fixed = 3\n",
    "        fixed_indices = random.sample(range(0, n_attributes[i]), k=n_fixed) # select which attributes are fixed\n",
    "        #fixed_indices = [0, 2, 1]\n",
    "        #fixed_value = random.randint(0, n_values[i]-1) # define a fixed value for this index\n",
    "        fixed_values = random.choices(range(0, n_values[i]), k=n_fixed)\n",
    "        #fixed_values = [0, 1, 2]\n",
    "        print(n_fixed, fixed_indices, fixed_values)\n",
    "        #index_threshold = 20000 # optional: define some index threshold to make sure that examples are not taken from the beginning of training\n",
    "        # TODO: adapt this loop such that multiple indices can be fixed\n",
    "        all_for_this_concept = []\n",
    "        for idx, (t_objects, t_fixed) in enumerate(concepts):\n",
    "            #if sum(t_fixed) == 1 and t_fixed[fixed_index] == 1:# and idx > index_threshold:\n",
    "            if sum(t_fixed) == n_fixed and all(t_fixed[fixed_index] == 1 for fixed_index in fixed_indices):\n",
    "                for t_object in t_objects:\n",
    "                    if all(t_object[fixed_index] == fixed_values[j] for j, fixed_index in enumerate(fixed_indices)):\n",
    "                        all_for_this_concept.append((idx, t_object, t_fixed, context_conds[idx], messages[idx]))\n",
    "                        fixed = t_fixed\n",
    "        #print(all_for_this_concept)                \n",
    "        if len(all_for_this_concept) > 0:\n",
    "            #sample = random.sample(all_for_this_concept, 20)\n",
    "            sample = all_for_this_concept\n",
    "            column_names = ['game_nr', 'object', 'fixed indices', 'context condition', 'message']\n",
    "            df = pd.DataFrame(sample, columns=column_names)\n",
    "            df.to_csv('analysis/quali_' + str(d) + '_' + str(setting) + '_'+g +'_' + str(sample[0][1]) + ',' + str(fixed) + 'all.csv', index=False)\n",
    "            print('saved ' + 'analysis/quali_' + str(d) + '_' + str(setting) +'_' + g + '_' + str(sample[0][1]) + ',' + str(fixed) + 'all.csv')\n",
    "        else:\n",
    "            raise ValueError(\"sample for dataset \" + str(d) + g + \" could not be generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_nr</th>\n",
       "      <th>object</th>\n",
       "      <th>fixed indices</th>\n",
       "      <th>context condition</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1384</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1384</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1183</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1798</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11, 1, 9, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1483</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 14, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>389</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 14, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1535</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1535</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1699</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 9, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1456</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>389</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 14, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>225</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1699</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 9, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1183</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1546</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[11, 1, 9, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>389</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 14, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1384</td>\n",
       "      <td>[0. 3. 2.]</td>\n",
       "      <td>[1. 1. 1.]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_nr      object fixed indices  context condition        message\n",
       "0      1384  [0. 3. 2.]    [1. 1. 1.]                  2   [1, 1, 1, 0]\n",
       "1        90  [0. 3. 2.]    [1. 1. 1.]                  1   [1, 1, 1, 0]\n",
       "2      1384  [0. 3. 2.]    [1. 1. 1.]                  2   [1, 1, 1, 0]\n",
       "3      1183  [0. 3. 2.]    [1. 1. 1.]                  1  [11, 1, 1, 0]\n",
       "4      1798  [0. 3. 2.]    [1. 1. 1.]                  0  [11, 1, 9, 0]\n",
       "5      1483  [0. 3. 2.]    [1. 1. 1.]                  2  [1, 1, 14, 0]\n",
       "6       389  [0. 3. 2.]    [1. 1. 1.]                  0  [1, 1, 14, 0]\n",
       "7      1535  [0. 3. 2.]    [1. 1. 1.]                  0  [11, 1, 1, 0]\n",
       "8      1535  [0. 3. 2.]    [1. 1. 1.]                  0  [11, 1, 1, 0]\n",
       "9      1699  [0. 3. 2.]    [1. 1. 1.]                  1   [1, 1, 9, 0]\n",
       "10     1456  [0. 3. 2.]    [1. 1. 1.]                  1   [1, 1, 1, 0]\n",
       "11       68  [0. 3. 2.]    [1. 1. 1.]                  2   [1, 1, 1, 0]\n",
       "12      389  [0. 3. 2.]    [1. 1. 1.]                  0  [1, 1, 14, 0]\n",
       "13      225  [0. 3. 2.]    [1. 1. 1.]                  0  [11, 1, 1, 0]\n",
       "14       90  [0. 3. 2.]    [1. 1. 1.]                  1   [1, 1, 1, 0]\n",
       "15     1699  [0. 3. 2.]    [1. 1. 1.]                  1   [1, 1, 9, 0]\n",
       "16     1183  [0. 3. 2.]    [1. 1. 1.]                  1  [11, 1, 1, 0]\n",
       "17     1546  [0. 3. 2.]    [1. 1. 1.]                  0  [11, 1, 9, 0]\n",
       "18      389  [0. 3. 2.]    [1. 1. 1.]                  0  [1, 1, 14, 0]\n",
       "19     1384  [0. 3. 2.]    [1. 1. 1.]                  2   [1, 1, 1, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('analysis/quali_(3,4)_standard_[0. 3. 2.],[1. 1. 1.].csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count messages used for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Define the directory and filename for the CSV file\n",
    "analysis_folder = 'analysis'\n",
    "csv_filename = os.path.join(analysis_folder, 'message_counts.csv')\n",
    "\n",
    "fieldnames = ['dataset', 'context_condition', 'unique_messages']\n",
    "\n",
    "# Check if the CSV file exists, if not, create it with headers\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "# Go through all datasets\n",
    "for i, d in enumerate(datasets):\n",
    "    for g in granularity_list:\n",
    "        if g != 'mixed':\n",
    "      # select first run\n",
    "            path_to_run = paths[i] + '/' + str(setting) + '/granularity_' + g + '/' + str(0) + '/'\n",
    "        else:\n",
    "            path_to_run = paths[i] + '/' + str(setting) +'/' + str(0) + '/'\n",
    "\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        print(path_to_interaction_train)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        unique_messages = set(tuple(msg) for msg in messages)  # Convert lists to tuples before adding to the set\n",
    "\n",
    "        mess_count = len(unique_messages)\n",
    "        # Check if the combination of dataset and context condition already exists in the CSV file\n",
    "        combination_exists = False\n",
    "        with open(csv_filename, 'r', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                if row['dataset'] == d and row['context_condition'] == g:\n",
    "                    combination_exists = True\n",
    "                    break\n",
    "\n",
    "        # If the combination exists, update the corresponding row\n",
    "        if combination_exists:\n",
    "            rows = []\n",
    "            with open(csv_filename, 'r', newline='') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    if row['dataset'] == d and row['context_condition'] == g:\n",
    "                        row['unique_messages'] = mess_count\n",
    "                    rows.append(row)\n",
    "            \n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(rows)\n",
    "        # If the combination does not exist, append a new row\n",
    "        else:\n",
    "            with open(csv_filename, 'a', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({'dataset': d, 'context_condition': g, 'unique_messages': mess_count})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>context_condition</th>\n",
       "      <th>unique_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(3,8)</td>\n",
       "      <td>fine</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(3,16)</td>\n",
       "      <td>fine</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>12925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(4,8)</td>\n",
       "      <td>fine</td>\n",
       "      <td>6636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>coarse</td>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>mixed</td>\n",
       "      <td>6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(5,4)</td>\n",
       "      <td>fine</td>\n",
       "      <td>4337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset context_condition  unique_messages\n",
       "0    (3,4)            coarse               33\n",
       "1    (3,4)             mixed              175\n",
       "2    (3,4)              fine              133\n",
       "3    (3,8)            coarse               41\n",
       "4    (3,8)             mixed              803\n",
       "5    (3,8)              fine              438\n",
       "6   (3,16)            coarse              133\n",
       "7   (3,16)             mixed             4032\n",
       "8   (3,16)              fine             1308\n",
       "9    (4,4)            coarse              204\n",
       "10   (4,4)             mixed             1312\n",
       "11   (4,4)              fine             1071\n",
       "12   (4,8)            coarse              788\n",
       "13   (4,8)             mixed            12925\n",
       "14   (4,8)              fine             6636\n",
       "15   (5,4)            coarse             1443\n",
       "16   (5,4)             mixed             6325\n",
       "17   (5,4)              fine             4337"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('analysis/message_counts.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts and messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
